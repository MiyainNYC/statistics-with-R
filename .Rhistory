install.packages("dplR")
?scale
3+4
3+4
install.packages('dplyr',dep = TRUE)
sd(c(5,8,2))
which.min(c(4,1,6))
sd(c(5,8,12))
q()
install.packages('ggplot2',dep = TRUE)
dirName = 'C:\Users\Miya\Desktop\Kaggle'
fileName = 'store.csv'
infile = file.path(dirName,fileName)
eeframe = read.csv(infile,header = True,stringsAsFactors = FALSE)
## Remove dots from column names.
pairs(~.,data=eeframe)
##load the data
dirName = 'C:\Users\Miya\Desktop\Kaggle'
fileName = 'store.csv'
infile = file.path(dirName,fileName)
eeframe = read.csv(infile,header = True,stringsAsFactors = FALSE)
## Remove dots from column names.
pairs(~.,data=eeframe)
##load the data
dirName = 'C:\Users\Miya\Desktop\Kaggle'
fileName = 'store.csv'
infile = file.path(dirName,fileName)
eeframe = read.csv(infile,header = True,stringsAsFactors = FALSE)
## Remove dots from column names.
pairs(~.,data=eeframe)
##load the data
dirName = 'C:\Users\Miya\Desktop\Kaggle'
fileName = 'store.csv'
infile = file.path(dirName,fileName)
eeframe = read.csv(infile,header = True,stringsAsFactors = FALSE)
## Remove dots from column names.
pairs(~.,data=eeframe)
##load the data
dirName = 'C:\Users\Miya\Desktop\Kaggle'
fileName = 'store.csv'
infile = file.path(dirName,fileName)
eeframe = read.csv(infile,header = True,stringsAsFactors = FALSE)
## Remove dots from column names.
pairs(~.,data=eeframe)
##load the data
dirName = 'C:\Users\Miya\Desktop\Kaggle'
fileName = 'store.csv'
infile = file.path(dirName,fileName)
eeframe = read.csv(infile,header = True,stringsAsFactors = FALSE)
## Remove dots from column names.
pairs(~.,data=eeframe)
##load the data
dirName = 'C:\Users\Miya\Desktop\Kaggle'
fileName = 'store.csv'
infile = file.path(dirName,fileName)
eeframe = read.csv(infile,header = True,stringsAsFactors = FALSE)
## Remove dots from column names.
Azure = FALSE
if(Azure){eeframe = mam1.mapInputPort(1)
mam1.mapOutPort('eeframe')}
pairs(~.,data=eeframe)
pairs(~ .,data = eeframe)
## Install ggplot2 (use a personal library if  prompted!)
## Install ggplot2 (use a personal library if  prompted!)
## install.packages('ggplot2', dep = TRUE)
## Use basic R graphics to create a pair-wise scatter plot
Azure = FALSE
if(Azure){
eeframe <- maml.mapInputPort(1)
maml.mapOutputPort('eeframe')
}
pairs(~ ., data = eeframe)
## Use ggplot2 to create conditioned scatter plots
library(ggplot2)
plotCols <- c("RelativeCompactness",
"SurfaceArea",
"WallArea",
"RoofArea",
"GlazingArea",
"GlazingAreaDistribution")
plotEE <- function(x){
title <- paste("Heating Load vs", x, "\n conditioned on OverallHeight and Orientation")
ggplot(eeframe, aes_string(x, "HeatingLoad")) +
geom_point() +
facet_grid(OverallHeight ~ Orientation) +
ggtitle(title) +
stat_smooth(method = "lm")
}
lapply(plotCols, plotEE)
## Create histograms
plotCols4 <- c("RelativeCompactness",
"SurfaceArea",
"WallArea",
"RoofArea",
"GlazingArea",
"GlazingAreaDistribution",
"HeatingLoad")
library(gridExtra)
eeHist <- function(x) {
title <- paste("Histogram of", x, "conditioned on OverallHeight")
ggplot(eeframe, aes_string(x)) +
geom_histogram(aes(y = ..density..)) +
facet_grid(. ~ OverallHeight) +
ggtitle(title) +
geom_density()
}
lapply(plotCols4, eeHist)
## Create box plots
eebox <- function(x) {
title <- paste("Box plot of", x, "by OverallHeight")
ggplot(eeframe, aes_string('OverallHeight', x)) +
geom_boxplot() +
ggtitle(title)
}
lapply(plotCols4, eebox)
"GlazingAreaDistribution")
"GlazingAreaDistribution")
book = ':\Users\Miya\Desktop\AzureML'
dirname = ':\Users\Miya\Desktop\AzureML'
dirname = 'C:\Users\Miya\Desktop\AzureML'
dirname = 'C:\\Users\Miya\Desktop\AzureML'
dirName = 'C:\Users\Miya\Desktop\AzureML'
dirName = 'C:\Users\Miya\Desktop\AzureML'
dirName = 'C:\Users\Miya\Desktop\AzureML'
fileName = 'book1.csv'
infile = file.path(dirName,fileName)
book = read.csv(infile,header = True,stringsAsFactors = FALSE)
dirName = 'C:\Users\Miya\Desktop\AzureML'
fileName = 'book1.csv'
infile = file.path(dirName,fileName)
book = read.csv(infile,header = True,stringsAsFactors = FALSE)
dirName = 'C:\Users\Miya\Desktop\AzureML'
fileName = 'book1.csv'
infile = file.path(dirName,fileName)
getwd()
book = read.csv("Book1.csv",stringsAsFactors = FALSE)
str(book)
book[1]
book[1]
book[2]
book$text[1]
book$Column1[1]
str(book$Column1[1])
strwrap(book$Column1[1])
library(tm)
install.packages(tm)
install.packages("tm")
library(tm)
corpus = Corpus(VectorSource(book$Column1))
strwrap(corpus[[1]])
corpus = tm_map(corpus,tolower)
corpus = tm_map(corpus,removePunctuation)
corpus = tm_map(corpus,removeWords,stopwords("english"))
corpus = tm_map(corpus,stemDocument)
strwrap(book$Column1[1])
strwrap(corpus$Column1[1])
strwrap(corpus[1])
dtm = DocumentTermMatrix(corpus)
corpus = tm_map(corpus,stemDocument)
corpus = tm_map(corpus,stripWhitespace)
dtm = DocumentTermMatrix(corpus)
strwrap(corpus[1])
getwd()
getwd(C:/Users/Miya/Desktop/Amazon
getwd(C:/Users/Miya/Desktop/Amazon)
getwd("C:/Users/Miya/Desktop/Amazon")
train = read.csv("eBayiPadTrain.csv",stringsAsFactors = FALSE)
library(tm)
library("tm")
test = read.csv("eBayiPadTest.csv",stringsAsFactors = FALSE)
corpusdescription = Corpus(VectorSource(c(train$description,test$description)))
corpusdescription
corpusdescription = tm_map(corpusdescription,content_transformer(tolower),lazy = TRUE)
corpusdescription = Corpus(VectorSource(c(train$description,test$description)))
summary(corpusdescription)
corpusdescription = Corpus(VectorSource(c(train$description,test$description)))
corpusdescription = tm_map(corpusdescription,content_transformer(tolower),lazy = TRUE)
corpusdescription = tm_map(corpusdescription,PlanTextDocument,lazy = TRUE)
corpusdescription = tm_map(corpusdescription,removePunctuation,lazy = TRUE)
corpusdescription = tm_map(corpusdescription,removeWords,stopwords("english"),lazy = TRUE)
corpusdescription = tm_map(corpusdescription,stemDocument,lazy = TRUE)
dtm = DocumentTermMatrix((dtm,0.99))
dtm = DocumentTermMatrix(dtm,0.99)
dtm = DocumentTermMatrix(corpusdescription)
corpusdescription = tm_map(corpusdescription,PlanTextDocument,lazy = TRUE)
dtm = DocumentTermMatrix(corpusdescription)
corpusdescription = tm_map(corpusdescription,PlainTextDocument,lazy = TRUE)
corpusdescription = tm_map(corpusdescription,removeWords,stopwords("english"),lazy = TRUE)
corpusdescription = tm_map(corpusdescription,removePunctuation,lazy = TRUE)
corpusdescription = tm_map(corpusdescription,stemDocument.lazy = TRUE)
corpusdescription = tm_map(corpusdescription,content_transformer(tolower),lazy = TRue)
corpusdescription = tm_map(corpusdescription,content_transformer(tolower),lazy = TRUE)
corpusdescription = tm_map(corpusdescription,PlainTextDocument,lazy = TRUE)
corpusdescription = tm_map(corpusdescription,removePunctuation,lazy=TRUE)
corpusdescription = tm_map(corpusdescription,removeWords,lazy=TRUE)
corpusdescription = tm_map(corpusdescription,stemDocument,lazy=TRUE)
dtm = DocumentTermMatrix(corpusdescription)
sparse = removeSparseTerms((dtm,0.99))
sparse = removeSparseTerms(dtm,0.99)
desriptionWords = as.data.frame(as.matrix(sparse))
dtm = DocumentTermMatrix(corpusdescription)
getwd()
gw()
wd()
getwd()
setwd(C:\Users\Miya\Desktop\specdata"")
?setwd
setwd(C:\Users\Miya\Desktop\specdata"")
setwd(C:\Users\Miya\Desktop\specdata")
setwd(C:/Users\Miya\Desktop\specdata")
setwd(C:/Users\Miya\Desktop")
setwd("C:/Users\Miya\Desktop")
setwd("C:\Users\Miya\Desktop")
getwd()
mean(pollutant_all, na.rm = TRUE)
dat <- data.frame()
for(i in id) {
}
ds <- (dat[, pollutant], na.rm = TRUE)
ds <- (dat, na.rm = TRUE)
## read the data into R
kings = scan("http://robjhyndman.com/tsdldata/misc/kings.dat", skip = 3
)
souvenirs = scan("http://robjhyndman.com/tsdldata/data/fancy.dat")
## store the data into timeseries using the funtion of ts(),for monthly frequency, you set the frequency of 12
kingstimeseries = ts(kings)
souvenirstimeseries = ts(souvenirs, frequency = 12, start = c(1987,1))
install.packages("TTR")
births = scan("http://robjhyndman.com/tsdldata/data/nybirths.dat")
birthstimeseries = ts(births,frequency =12, start = c(1946,1))
birthstimeseriescomponents = decompose(birthstimeseries)
birthstimeseriescomponents = decompose(birthstimeseries)
## the decompose function returns a list object as its result, where the estimates of the seasonal component, trend component and irregular component are stored in names elements of that list objects, called:'seasonal','trend', and'random'
## the estimated values of the seasonal, trend and irregular components are now stored in variables: birthstimeseriescomponents$seasonal,birthstimeseriescomponents$trend and $random
birthstimeseriescomponents$seasonal
g1 <- graph( edges=c(1,2, 2,3, 3,1), n=3, directed=F )
install.packages('devtools')
library(devtools)
setwd("C:/Users/Miya/OneDrive/Miya'sGithub/statistics-with-R")
load('selected_nzes2011.Rdata')
library(dplyr)
names(selected_nzes2011)
selected_nzes2011 %>% select(jpartyvote, jdiffvoting,X_singlefav) %>% str()
help("grep")
grep("singlefav", names(selected_nzes2011), ignore.case = FALSE)
names(selected_nzes2011)[107]
selected_nzes2011%>%group_by(jpartyvote)%>%summarise(count = n())
selected_nzes2011%>% filter(jpartyvote !="Don't know")%>%group_by(jpartyvote)%>%summarise(count = n())
selected_nzes2011%>%group_by(X_singlefav) %>% summarise(count = n())
selected_nzes2011 %>% filter(!is.na(X_singlefav))%>%group_by(X_singlefav)%>% summarise(count = n())
selected_nzes2011 %>% filter(!is.na(X_singlefav), jpartyvote != "Don't know")%>%group_by(X_singlefav)%>% summarise(count = n())
selected_nzes2011 = selected_nzes2011 %>% mutate(samparty = ifelse(jpartyvote == X_singlefav, "same"," different"))
selected_nzes2011 %>% group_by(jpartyvote, X_singlefav, sameparty)%>%summarise(count = n())
selected_nzes2011 = selected_nzes2011 %>% mutate(sameparty = ifelse(jpartyvote == X_singlefav, "same"," different"))
selected_nzes2011 %>% group_by(jpartyvote, X_singlefav, sameparty)%>%summarise(count = n())
selected_nzes2011 %>% group_by(jpartyvote, X_singlefav, sameparty) %>% summarise(count = n())%>%filter(sameparty == 'same')
selected_nzes2011 %>% group_by(jpartyvote, X_singlefav, sameparty) %>% summarise(count = n())%>%filter(sameparty == 'different')
selected_nzes2011 %>% group_by(jpartyvote, X_singlefav, sameparty) %>% summarise(count = n())%>%filter(sameparty == 'different')
selected_nzes2011 %>% group_by(jpartyvote, X_singlefav, sameparty) %>% summarise(count = n())%>%filter(sameparty == 'same')
selected_nzes2011 %>% group_by(jpartyvote, X_singlefav, sameparty) %>% summarise(count = n())%>%filter(sameparty == 'different')
selected_nzes2011 %>% group_by(jpartyvote, X_singlefav, sameparty) %>% summarise(count = n())%>%filter(is.na(sameparty))
str(selected_nzes2011$jnzflike)
str(selected_nzes2011$jage)
selected_nzes2011 %>% group_by(jnzflike) %>% summarise(count = n())
selected_nzes2011 %>% group_by(jnzflike) %>% summarise(count = n()) %>% arrange(desc(count))
selected_nzes2011 %>% summarise(agemean = mean(jage), agemedian = median(jage), agesd = sd(jage), agemin = min(jage), agemax = max(jage))
selected_nzes2011 %>% filter(!is.na(jage) %>%  summarise(agemean = mean(jage), agemedian = median(jage), agesd = sd(jage), agemin = min(jage), agemax = max(jage))
selected_nzes2011 %>% filter(!is.na(jage)) %>%  summarise(agemean = mean(jage), agemedian = median(jage), agesd = sd(jage), agemin = min(jage), agemax = max(jage))
selected_nzes2011 %>% filter(!is.na(jage)) %>%  summarise(agemean = mean(jage), agemedian = median(jage), agesd = sd(jage), agemin = min(jage), agemax = max(jage))
summarise(count = n())
selected_nzes2011 %>% mutate(retireage = ifelse(jage >= 65, "retired age","working age"))%>%group_by(retireage)%>%summarise(count = n())
selected_nzes2011 = selected_nzes2011%>%mutate(numlikenzf = as.numeric(jnzflike))
selected_nzes2011 %>% group_by(jnzflike,numlikenzf)%>%summarise(count = n())
selected_nzes2011 = selected_nzes2011%>%mutate(numlikenzf = as.numeric(as.character(jnzflike)))
selected_nzes2011 %>% group_by(jnzflike, numlikenzf)%>%summarise(count = n())
libary(shiny)
library(shiny)
library(devtools)
install_github("StatsWithR/statsr")
install_github("StatsWithR/statsr")
install_github("StatsWithR/statsr", force = True)
install_github("StatsWithR/statsr", force = TRUE)
setwd("C:/Users/Miya/OneDrive/Miya'sGithub/statistics-with-R")
install.packages("magrittr")
install.packages("magrittr")
library(magrittr)
setwd("C:/Users/Miya/OneDrive")
setwd("C:/Users/Miya/OneDrive/Miya'sGithub/statistics-with-R")
install.packages('devtools')
library(devtools)
install_github("StatsWithR/statsr")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages('shiny')
bandit_sim()
suppressMessages(library(magrittr))
suppressMessages(library(statsr))
bandit_sim()
bandit_posterior(data = data.frame(machine=1L, outcome="W"))
bandit_posterior(data = data.frame(machine=c(1L,1L), outcome=c("W","L")))
data1 = data.frame(machine=c(1L), outcome=c("W"))
data2 = data.frame(machine=c(1L), outcome=c("L"))
bandit_posterior(data1) %>% bandit_posterior(data2, prior=.)
data = data.frame(machine = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L),
outcome = c("L", "W", "W", "W", "L", "L", "L", "W", "W", "L",
"L", "W", "W", "W", "W", "L", "W", "L", "L", "L",
"W", "L", "L", "W", "L", "L", "L", "W", "L", "W",
"L", "L", "W", "L", "L", "L", "W", "W", "L", "W"))
plot_bandit_posterior(data)
library(devtools)
install_github("StatsWithR/statsr")
install_github("StatsWithR/statsr",force = TRUE)
library('magrittr')
library(shiny)
library(magrittr)
install.packages('shiny')
install.packages("shiny")
library(dplyr)
library(devtools)
